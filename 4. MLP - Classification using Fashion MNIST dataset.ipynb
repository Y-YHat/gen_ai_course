{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement: Create a classification model for the Fashion MNIST\n",
        "\n",
        "The objective is to create a classification model for the Fashion MNIST dataset using a Multi-Layer Perceptron (MLP).\n",
        "\n",
        "We'll follow these steps:\n",
        "\n",
        "### 1. Data Preprocessing\n",
        "- **Loading the Data**: Fashion MNIST is a dataset of Zalando's article images, with 60,000 training samples and 10,000 test samples. Each sample is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "- **Normalization**: We normalize the pixel values (ranging from 0 to 255) to a scale of 0 to 1. This improves the training efficiency.\n",
        "- **Reshaping for MLP**: Since we are using an MLP, we need to reshape the 28x28 images into a flat array of 784 pixels.\n",
        "\n",
        "### 2. Building the MLP Model\n",
        "- **Dense Layers**: These are fully connected neural layers. The first layer needs to know the input shape (784 in this case).\n",
        "- **Activation Functions**: 'ReLU' is used for non-linear transformations. The final layer uses 'softmax' for a probability distribution over 10 classes.\n",
        "\n",
        "### 3. Compiling the Model\n",
        "- **Optimizer**: 'Adam' is a popular choice for its adaptive learning rate properties.\n",
        "- **Loss Function**: 'sparse_categorical_crossentropy' is suitable for multi-class classification problems.\n",
        "- **Metrics**: We'll use 'accuracy' to understand the performance.\n",
        "\n",
        "### 4. Training the Model\n",
        "- We train the model using the `fit` method, specifying epochs and batch size.\n",
        "\n",
        "### 5. Evaluating the Model\n",
        "- The `evaluate` method is used to test the model on the test set.\n",
        "\n",
        "The notebook contains one exercise in total:\n",
        "\n",
        "* [Exercise 1](#ex_1)"
      ],
      "metadata": {
        "id": "7-1RI2LOhzW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z1Yqb6DdkCiq",
        "outputId": "a8ef65df-37ea-4cf7-c23f-0926a900c8ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yKlxud86hcIh",
        "outputId": "a5c99b73-bcb5-4168-8e31-7673898e5109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.5162 - accuracy: 0.8191\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3850 - accuracy: 0.8628\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3459 - accuracy: 0.8753\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3222 - accuracy: 0.8835\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3019 - accuracy: 0.8896\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.2881 - accuracy: 0.8943\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2759 - accuracy: 0.8997\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2650 - accuracy: 0.9022\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2554 - accuracy: 0.9053\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2457 - accuracy: 0.9078\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8769\n",
            "Test accuracy: 0.8769000172615051\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape data for MLP input\n",
        "train_images = train_images.reshape((-1, 28*28))\n",
        "test_images = test_images.reshape((-1, 28*28))\n",
        "\n",
        "# Build the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the model's accuracy on the Fashion MNIST dataset, we can experiment with various techniques. Here are some strategies:\n",
        "\n",
        "1. **Increase Model Complexity**: Add more layers or increase the number of neurons in each layer to capture more complex patterns in the data.\n",
        "\n",
        "2. **Regularization**: Implement dropout or L1/L2 regularization to reduce overfitting.\n",
        "\n",
        "3. **Advanced Optimizers**: Experiment with different optimizers like SGD or RMSprop.\n",
        "\n",
        "4. **Learning Rate Scheduling**: Adjust the learning rate during training.\n",
        "\n",
        "5. **Data Augmentation**: Although not typical for MLPs, slight modifications to the input data can make the model more robust.\n",
        "\n",
        "6. **Early Stopping**: Stop training when the validation accuracy stops improving.\n",
        "\n",
        "7. **Hyperparameter Tuning**: Experiment with different activation functions, batch sizes, and epochs.\n",
        "\n",
        "8. **Batch Normalization**: This can help in faster convergence and overall performance improvement.\n",
        "\n",
        "Let's modify the previous code to incorporate some of these strategies."
      ],
      "metadata": {
        "id": "yL1TJaEzjvVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Modified MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
        "model.add(BatchNormalization())  # Batch normalization layer\n",
        "model.add(Dropout(0.5))         # Dropout layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())  # Another batch normalization layer\n",
        "model.add(Dropout(0.5))         # Another dropout layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Train the model with validation split\n",
        "model.fit(train_images, train_labels, epochs=50, batch_size=64,\n",
        "          validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "GkitFh5aij7B",
        "outputId": "b9197df3-1dbd-4e2c-8dfd-40fba8cee4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 9s 10ms/step - loss: 0.7263 - accuracy: 0.7501 - val_loss: 0.4576 - val_accuracy: 0.8282\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.5251 - accuracy: 0.8146 - val_loss: 0.4268 - val_accuracy: 0.8432\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4821 - accuracy: 0.8276 - val_loss: 0.4034 - val_accuracy: 0.8526\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4667 - accuracy: 0.8328 - val_loss: 0.3914 - val_accuracy: 0.8532\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.4535 - accuracy: 0.8380 - val_loss: 0.3877 - val_accuracy: 0.8581\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.4437 - accuracy: 0.8428 - val_loss: 0.3802 - val_accuracy: 0.8586\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.4295 - accuracy: 0.8474 - val_loss: 0.3724 - val_accuracy: 0.8631\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4154 - accuracy: 0.8509 - val_loss: 0.3601 - val_accuracy: 0.8698\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.4148 - accuracy: 0.8519 - val_loss: 0.3621 - val_accuracy: 0.8678\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4049 - accuracy: 0.8549 - val_loss: 0.3662 - val_accuracy: 0.8612\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.4027 - accuracy: 0.8553 - val_loss: 0.3569 - val_accuracy: 0.8683\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3986 - accuracy: 0.8558 - val_loss: 0.3670 - val_accuracy: 0.8637\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3982 - accuracy: 0.8572 - val_loss: 0.3502 - val_accuracy: 0.8749\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3883 - accuracy: 0.8619 - val_loss: 0.3599 - val_accuracy: 0.8700\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3844 - accuracy: 0.8619 - val_loss: 0.3520 - val_accuracy: 0.8713\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3774 - accuracy: 0.8643 - val_loss: 0.3324 - val_accuracy: 0.8798\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.3728 - accuracy: 0.8647 - val_loss: 0.3502 - val_accuracy: 0.8725\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3814 - accuracy: 0.8624 - val_loss: 0.3443 - val_accuracy: 0.8729\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3739 - accuracy: 0.8642 - val_loss: 0.3381 - val_accuracy: 0.8767\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3773 - accuracy: 0.8641 - val_loss: 0.3416 - val_accuracy: 0.8777\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3673 - accuracy: 0.8664 - val_loss: 0.3272 - val_accuracy: 0.8792\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3639 - accuracy: 0.8674 - val_loss: 0.3285 - val_accuracy: 0.8808\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3644 - accuracy: 0.8673 - val_loss: 0.3361 - val_accuracy: 0.8791\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3546 - accuracy: 0.8711 - val_loss: 0.3241 - val_accuracy: 0.8822\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3551 - accuracy: 0.8711 - val_loss: 0.3294 - val_accuracy: 0.8794\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.3523 - accuracy: 0.8731 - val_loss: 0.3239 - val_accuracy: 0.8826\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3553 - accuracy: 0.8697 - val_loss: 0.3448 - val_accuracy: 0.8765\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.3481 - accuracy: 0.8740 - val_loss: 0.3264 - val_accuracy: 0.8797\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.3468 - accuracy: 0.8733 - val_loss: 0.3356 - val_accuracy: 0.8777\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3459 - accuracy: 0.8732 - val_loss: 0.3261 - val_accuracy: 0.8777\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3448 - accuracy: 0.8741 - val_loss: 0.3169 - val_accuracy: 0.8832\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3396 - accuracy: 0.8776 - val_loss: 0.3228 - val_accuracy: 0.8825\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3345 - accuracy: 0.8783 - val_loss: 0.3302 - val_accuracy: 0.8835\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3390 - accuracy: 0.8771 - val_loss: 0.3143 - val_accuracy: 0.8861\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.3374 - accuracy: 0.8771 - val_loss: 0.3233 - val_accuracy: 0.8853\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3373 - accuracy: 0.8770 - val_loss: 0.3209 - val_accuracy: 0.8870\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.3357 - accuracy: 0.8787 - val_loss: 0.3084 - val_accuracy: 0.8880\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3328 - accuracy: 0.8784 - val_loss: 0.3419 - val_accuracy: 0.8759\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.3265 - accuracy: 0.8797 - val_loss: 0.3205 - val_accuracy: 0.8844\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.3327 - accuracy: 0.8772 - val_loss: 0.3210 - val_accuracy: 0.8839\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3360 - accuracy: 0.8767 - val_loss: 0.3231 - val_accuracy: 0.8829\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3313 - accuracy: 0.8778 - val_loss: 0.3172 - val_accuracy: 0.8846\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3447 - accuracy: 0.8780\n",
            "Test accuracy: 0.878000020980835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy decreased slightly in this case. This outcome highlights an important aspect of machine learning: improvements in model architecture don't always lead to better performance, and sometimes simpler models can outperform more complex ones, especially on smaller datasets like Fashion MNIST.\n",
        "\n",
        "Here are a few additional steps you can take to try and improve the model's performance:\n",
        "\n",
        "1. **Adjust the Dropout Rate**: The dropout rate of 0.5 might be too high, causing the model to lose relevant information. Try reducing it to 0.3 or 0.2.\n",
        "\n",
        "2. **Fine-Tune the Model Complexity**: The addition of more neurons might have made the model too complex. Try reducing the number of neurons in the dense layers.\n",
        "\n",
        "3. **Experiment with Different Optimizers**: While Adam is a strong general-purpose optimizer, sometimes others like SGD (with a momentum) or RMSprop might yield better results for specific problems.\n",
        "\n",
        "4. **Modify the Learning Rate**: Adjusting the learning rate of the Adam optimizer could also lead to better results. A lower learning rate with more epochs can sometimes achieve better generalization.\n",
        "\n",
        "5. **Experiment with Batch Sizes**: Smaller or larger batch sizes can impact the model's ability to generalize and learn effectively.\n",
        "\n",
        "6. **Cross-Validation**: Instead of a single validation split, use k-fold cross-validation for a more robust estimate of model performance.\n",
        "\n",
        "Let's adjust the code with some of these suggestions."
      ],
      "metadata": {
        "id": "lGXeENRJjzVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the model architecture and training parameters\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.3))         # Reduced dropout rate\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))         # Reduced dropout rate\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with a modified optimizer\n",
        "model.compile(optimizer='adam',  # You can experiment with learning rate here\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with a different batch size\n",
        "model.fit(train_images, train_labels, epochs=50, batch_size=32,  # Smaller batch size\n",
        "          validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "T9z3khhbjrVp",
        "outputId": "b2ceac48-e884-4580-8007-51c635cbd494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6570 - accuracy: 0.7646 - val_loss: 0.4314 - val_accuracy: 0.8473\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4766 - accuracy: 0.8302 - val_loss: 0.4142 - val_accuracy: 0.8412\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4337 - accuracy: 0.8437 - val_loss: 0.3832 - val_accuracy: 0.8590\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4144 - accuracy: 0.8503 - val_loss: 0.3673 - val_accuracy: 0.8685\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3970 - accuracy: 0.8566 - val_loss: 0.3656 - val_accuracy: 0.8668\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3778 - accuracy: 0.8629 - val_loss: 0.3418 - val_accuracy: 0.8741\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3670 - accuracy: 0.8654 - val_loss: 0.3470 - val_accuracy: 0.8773\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3612 - accuracy: 0.8678 - val_loss: 0.3349 - val_accuracy: 0.8809\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3563 - accuracy: 0.8692 - val_loss: 0.3469 - val_accuracy: 0.8750\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3485 - accuracy: 0.8708 - val_loss: 0.3302 - val_accuracy: 0.8808\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3426 - accuracy: 0.8735 - val_loss: 0.3414 - val_accuracy: 0.8767\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3348 - accuracy: 0.8776 - val_loss: 0.3275 - val_accuracy: 0.8828\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3335 - accuracy: 0.8773 - val_loss: 0.3259 - val_accuracy: 0.8798\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3247 - accuracy: 0.8797 - val_loss: 0.3271 - val_accuracy: 0.8827\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3204 - accuracy: 0.8821 - val_loss: 0.3246 - val_accuracy: 0.8830\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3188 - accuracy: 0.8827 - val_loss: 0.3196 - val_accuracy: 0.8836\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3120 - accuracy: 0.8837 - val_loss: 0.3239 - val_accuracy: 0.8813\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3109 - accuracy: 0.8849 - val_loss: 0.3181 - val_accuracy: 0.8862\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3083 - accuracy: 0.8854 - val_loss: 0.3172 - val_accuracy: 0.8864\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3066 - accuracy: 0.8876 - val_loss: 0.3335 - val_accuracy: 0.8873\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3025 - accuracy: 0.8880 - val_loss: 0.3310 - val_accuracy: 0.8835\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3006 - accuracy: 0.8885 - val_loss: 0.3212 - val_accuracy: 0.8867\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2967 - accuracy: 0.8903 - val_loss: 0.3309 - val_accuracy: 0.8846\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2942 - accuracy: 0.8904 - val_loss: 0.3237 - val_accuracy: 0.8863\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8786\n",
            "Test accuracy: 0.878600001335144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test accuracy has improved to 0.8778, which is a positive outcome. This result indicates that the adjustments made to the model architecture and training parameters were beneficial.\n",
        "\n",
        "However, achieving higher accuracy on a dataset like Fashion MNIST can be challenging, especially with a simple model like a Multi-Layer Perceptron (MLP). To potentially achieve even better results, consider the following additional steps:\n",
        "\n",
        "1. **Feature Engineering**: Although this is more limited with image data and MLPs, ensuring the input data is as informative and clean as possible is crucial.\n",
        "\n",
        "2. **Ensemble Methods**: Combine predictions from several models to improve accuracy. For example, train multiple MLPs with different architectures and average their predictions.\n",
        "\n",
        "3. **Convolutional Neural Networks (CNNs)**: For image data, CNNs are generally more effective than MLPs. They can capture spatial hierarchies in the data better due to their convolutional layers.\n",
        "\n",
        "4. **Hyperparameter Optimization**: Use techniques like grid search or random search to systematically explore different hyperparameter combinations.\n",
        "\n",
        "5. **Advanced Regularization Techniques**: Experiment with other regularization methods like L1 regularization or different dropout configurations.\n",
        "\n",
        "Let's adjust the code with some of these suggestions."
      ],
      "metadata": {
        "id": "rmWbPC5gmHZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build a simple CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation='relu'))\n",
        "cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(train_images_cnn, train_labels, epochs=10, batch_size=64,\n",
        "              validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images_cnn, test_labels)\n",
        "\n",
        "print('CNN Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "BKPmmHqImJEi",
        "outputId": "df92e95c-108b-47f0-9aab-74534f8140c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 40s 52ms/step - loss: 0.5448 - accuracy: 0.8042 - val_loss: 0.3909 - val_accuracy: 0.8625\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.3584 - accuracy: 0.8710 - val_loss: 0.3686 - val_accuracy: 0.8653\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.3056 - accuracy: 0.8913 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.2726 - accuracy: 0.9004 - val_loss: 0.2792 - val_accuracy: 0.9007\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.2477 - accuracy: 0.9092 - val_loss: 0.2746 - val_accuracy: 0.8995\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.2277 - accuracy: 0.9163 - val_loss: 0.2681 - val_accuracy: 0.9002\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.2099 - accuracy: 0.9235 - val_loss: 0.2538 - val_accuracy: 0.9110\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.1917 - accuracy: 0.9284 - val_loss: 0.2600 - val_accuracy: 0.9070\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.1757 - accuracy: 0.9336 - val_loss: 0.2476 - val_accuracy: 0.9090\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1623 - accuracy: 0.9398 - val_loss: 0.2585 - val_accuracy: 0.9097\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2753 - accuracy: 0.9046\n",
            "CNN Test accuracy: 0.9046000242233276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ex_1\"></a>\n",
        "## Exercise 1: Improve the accuracy of the MLP model\n",
        "1. Try different architectures and hyperparameters.\n",
        "2. Use regularization techniques like L1 or L2 regularization.\n",
        "3. Use dropout to reduce overfitting.\n",
        "\n",
        "Referans link: https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/"
      ],
      "metadata": {
        "id": "WACMOuHj3wp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build a more complex CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn_model.add(Dropout(0.3))  # Dropout layer to reduce overfitting\n",
        "cnn_model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model with more epochs and a smaller batch size\n",
        "cnn_model.fit(train_images_cnn, train_labels, epochs=15, batch_size=32,\n",
        "              validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images_cnn, test_labels)\n",
        "\n",
        "print('CNN Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "zw_q_p9SpAfF",
        "outputId": "840e1180-f262-4bf9-ccf8-5b596f8621d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 [==============================] - 51s 33ms/step - loss: 0.7062 - accuracy: 0.7955 - val_loss: 0.4916 - val_accuracy: 0.8634\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 47s 31ms/step - loss: 0.4946 - accuracy: 0.8609 - val_loss: 0.4457 - val_accuracy: 0.8727\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 49s 33ms/step - loss: 0.4394 - accuracy: 0.8773 - val_loss: 0.3951 - val_accuracy: 0.8919\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 49s 33ms/step - loss: 0.4138 - accuracy: 0.8843 - val_loss: 0.3874 - val_accuracy: 0.8912\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 50s 33ms/step - loss: 0.3961 - accuracy: 0.8899 - val_loss: 0.3712 - val_accuracy: 0.8967\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 47s 32ms/step - loss: 0.3760 - accuracy: 0.8970 - val_loss: 0.3561 - val_accuracy: 0.9010\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 48s 32ms/step - loss: 0.3663 - accuracy: 0.8999 - val_loss: 0.3788 - val_accuracy: 0.8931\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 47s 31ms/step - loss: 0.3572 - accuracy: 0.9028 - val_loss: 0.3664 - val_accuracy: 0.8973\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 47s 31ms/step - loss: 0.3511 - accuracy: 0.9048 - val_loss: 0.3415 - val_accuracy: 0.9061\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 49s 33ms/step - loss: 0.3480 - accuracy: 0.9065 - val_loss: 0.3570 - val_accuracy: 0.9057\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 47s 32ms/step - loss: 0.3380 - accuracy: 0.9099 - val_loss: 0.3581 - val_accuracy: 0.8983\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 50s 33ms/step - loss: 0.3300 - accuracy: 0.9131 - val_loss: 0.3489 - val_accuracy: 0.9087\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 51s 34ms/step - loss: 0.3288 - accuracy: 0.9136 - val_loss: 0.3447 - val_accuracy: 0.9090\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 47s 32ms/step - loss: 0.3252 - accuracy: 0.9163 - val_loss: 0.3415 - val_accuracy: 0.9075\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 50s 33ms/step - loss: 0.3213 - accuracy: 0.9167 - val_loss: 0.3479 - val_accuracy: 0.9097\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3631 - accuracy: 0.9009\n",
            "CNN Test accuracy: 0.9009000062942505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define hyperparameters\n",
        "learning_rate = 0.0001\n",
        "l2_regularizer_rate = 0.01\n",
        "dropout_rate = 0.5\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build a more complex CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_regularizer_rate)))\n",
        "cnn_model.add(Dropout(dropout_rate))  # Dropout layer to reduce overfitting\n",
        "cnn_model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_regularizer_rate)))\n",
        "cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(train_images_cnn, train_labels, epochs=epochs, batch_size=batch_size,\n",
        "              validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images_cnn, test_labels)\n",
        "\n",
        "print('CNN Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "0rAHlJ_yqFmv",
        "outputId": "3f21fdcd-6397-496f-8bb1-dfa490a97983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "750/750 [==============================] - 45s 58ms/step - loss: 2.7514 - accuracy: 0.5919 - val_loss: 1.6277 - val_accuracy: 0.7634\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 1.4827 - accuracy: 0.7464 - val_loss: 1.2018 - val_accuracy: 0.7931\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 1.1629 - accuracy: 0.7741 - val_loss: 0.9895 - val_accuracy: 0.8092\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.9871 - accuracy: 0.7921 - val_loss: 0.8624 - val_accuracy: 0.8180\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.8768 - accuracy: 0.8014 - val_loss: 0.7769 - val_accuracy: 0.8240\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.7970 - accuracy: 0.8110 - val_loss: 0.7044 - val_accuracy: 0.8362\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.7392 - accuracy: 0.8199 - val_loss: 0.6719 - val_accuracy: 0.8328\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6914 - accuracy: 0.8238 - val_loss: 0.6194 - val_accuracy: 0.8478\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6553 - accuracy: 0.8317 - val_loss: 0.5907 - val_accuracy: 0.8492\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6260 - accuracy: 0.8366 - val_loss: 0.5746 - val_accuracy: 0.8507\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6028 - accuracy: 0.8406 - val_loss: 0.5577 - val_accuracy: 0.8529\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.5816 - accuracy: 0.8431 - val_loss: 0.5272 - val_accuracy: 0.8608\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 45s 59ms/step - loss: 0.5642 - accuracy: 0.8474 - val_loss: 0.5243 - val_accuracy: 0.8567\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.5510 - accuracy: 0.8499 - val_loss: 0.5042 - val_accuracy: 0.8610\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.5371 - accuracy: 0.8505 - val_loss: 0.4948 - val_accuracy: 0.8663\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.5259 - accuracy: 0.8538 - val_loss: 0.4781 - val_accuracy: 0.8683\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.5144 - accuracy: 0.8576 - val_loss: 0.4710 - val_accuracy: 0.8687\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.5060 - accuracy: 0.8582 - val_loss: 0.4702 - val_accuracy: 0.8713\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.4990 - accuracy: 0.8604 - val_loss: 0.4598 - val_accuracy: 0.8689\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4928 - accuracy: 0.8624 - val_loss: 0.4464 - val_accuracy: 0.8777\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.4605 - accuracy: 0.8735\n",
            "CNN Test accuracy: 0.8734999895095825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build a simple CNN model\n",
        "mnist_model = Sequential()\n",
        "mnist_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "mnist_model.add(MaxPooling2D((2, 2)))\n",
        "mnist_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "mnist_model.add(MaxPooling2D((2, 2)))\n",
        "mnist_model.add(Flatten())\n",
        "mnist_model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "mnist_model.add(Dropout(0.3))  # Dropout layer to reduce overfitting\n",
        "mnist_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "mnist_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "mnist_model.fit(train_images_cnn, train_labels, epochs=15, batch_size=64,\n",
        "                validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = mnist_model.evaluate(test_images_cnn, test_labels)\n",
        "\n",
        "print('MNIST Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "UqbHVdAUurHs",
        "outputId": "bc29b003-755b-4e91-cd81-340dd3fa6aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 44s 57ms/step - loss: 1.1412 - accuracy: 0.6675 - val_loss: 0.7349 - val_accuracy: 0.7878\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.7341 - accuracy: 0.7898 - val_loss: 0.6524 - val_accuracy: 0.8166\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 45s 59ms/step - loss: 0.6516 - accuracy: 0.8172 - val_loss: 0.5937 - val_accuracy: 0.8398\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6006 - accuracy: 0.8353 - val_loss: 0.5560 - val_accuracy: 0.8500\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.5672 - accuracy: 0.8454 - val_loss: 0.5334 - val_accuracy: 0.8532\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 45s 59ms/step - loss: 0.5347 - accuracy: 0.8525 - val_loss: 0.5050 - val_accuracy: 0.8620\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.5127 - accuracy: 0.8563 - val_loss: 0.4890 - val_accuracy: 0.8624\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4902 - accuracy: 0.8626 - val_loss: 0.4682 - val_accuracy: 0.8681\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4721 - accuracy: 0.8675 - val_loss: 0.4583 - val_accuracy: 0.8702\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4593 - accuracy: 0.8684 - val_loss: 0.4391 - val_accuracy: 0.8768\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.4408 - accuracy: 0.8749 - val_loss: 0.4301 - val_accuracy: 0.8745\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4281 - accuracy: 0.8758 - val_loss: 0.4199 - val_accuracy: 0.8764\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4154 - accuracy: 0.8786 - val_loss: 0.4050 - val_accuracy: 0.8831\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4069 - accuracy: 0.8801 - val_loss: 0.3974 - val_accuracy: 0.8832\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.3955 - accuracy: 0.8843 - val_loss: 0.3868 - val_accuracy: 0.8851\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3982 - accuracy: 0.8813\n",
            "MNIST Test accuracy: 0.8812999725341797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Normalize the images to [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build an improved CNN model\n",
        "improved_cnn_model = Sequential()\n",
        "improved_cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "improved_cnn_model.add(BatchNormalization())\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "improved_cnn_model.add(BatchNormalization())\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "improved_cnn_model.add(BatchNormalization())\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Flatten())\n",
        "improved_cnn_model.add(Dense(128, activation='relu'))\n",
        "improved_cnn_model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
        "improved_cnn_model.add(Dense(64, activation='relu'))\n",
        "improved_cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape data for MLP input\n",
        "train_images = train_images.reshape((-1, 28*28))\n",
        "test_images = test_images.reshape((-1, 28*28))\n",
        "\n",
        "# Define a learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    initial_learning_rate = 0.001\n",
        "    decay = 0.9\n",
        "    lr = initial_learning_rate * decay ** epoch\n",
        "    return lr\n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Compile the model with the Adam optimizer\n",
        "improved_cnn_model.compile(optimizer=Adam(),\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the learning rate scheduler callback\n",
        "improved_cnn_model.fit(train_images_cnn, train_labels, epochs=15, batch_size=64,\n",
        "                       validation_split=0.2, callbacks=[lr_scheduler])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = improved_cnn_model.evaluate(test_images_cnn, test_labels)\n",
        "print('Improved CNN Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "T3h6vwQGyTA8",
        "outputId": "e98b0238-5069-4f8c-d294-00c4d95647c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5dfb71950b0e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Normalize the images to [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Reshape data for CNN input\n",
        "train_images_cnn = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images_cnn = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Build a more complex CNN model\n",
        "improved_cnn_model = Sequential()\n",
        "improved_cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "improved_cnn_model.add(MaxPooling2D((2, 2)))\n",
        "improved_cnn_model.add(Flatten())\n",
        "improved_cnn_model.add(Dense(256, activation='relu'))\n",
        "improved_cnn_model.add(Dropout(0.5))\n",
        "improved_cnn_model.add(Dense(128, activation='relu'))\n",
        "improved_cnn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Add Batch Normalization layers\n",
        "improved_cnn_model.add(BatchNormalization())\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "improved_cnn_model.compile(optimizer='adam',\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "improved_cnn_model.fit(train_images_cnn, train_labels, epochs=15, batch_size=64,\n",
        "                       validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = improved_cnn_model.evaluate(test_images_cnn, test_labels)\n",
        "\n",
        "print('Improved CNN Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "UpyDC2qYG8Oy",
        "outputId": "c08df0b0-4554-4e92-cd2b-90d37dfcd3df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 46s 60ms/step - loss: 1.8640 - accuracy: 0.5357 - val_loss: 0.9140 - val_accuracy: 0.7232\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 48s 65ms/step - loss: 1.1927 - accuracy: 0.6535 - val_loss: 0.9985 - val_accuracy: 0.6665\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.9283 - accuracy: 0.7179 - val_loss: 0.8297 - val_accuracy: 0.7347\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 1.1029 - accuracy: 0.6861 - val_loss: 0.8834 - val_accuracy: 0.6547\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 1.0937 - accuracy: 0.6562 - val_loss: 0.7761 - val_accuracy: 0.7158\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 1.0270 - accuracy: 0.6577 - val_loss: 0.7512 - val_accuracy: 0.7333\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 45s 61ms/step - loss: 0.9352 - accuracy: 0.6983 - val_loss: 0.7459 - val_accuracy: 0.7482\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.8172 - accuracy: 0.7314 - val_loss: 0.6864 - val_accuracy: 0.7598\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.7831 - accuracy: 0.7380 - val_loss: 0.6356 - val_accuracy: 0.7700\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6914 - accuracy: 0.7665 - val_loss: 0.6789 - val_accuracy: 0.7882\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 46s 61ms/step - loss: 0.9101 - accuracy: 0.7151 - val_loss: 1.2794 - val_accuracy: 0.5613\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.8646 - accuracy: 0.7331 - val_loss: 0.5895 - val_accuracy: 0.7921\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6614 - accuracy: 0.7881 - val_loss: 0.6147 - val_accuracy: 0.7997\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6451 - accuracy: 0.7896 - val_loss: 0.5917 - val_accuracy: 0.7811\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 45s 61ms/step - loss: 0.6490 - accuracy: 0.7855 - val_loss: 0.5506 - val_accuracy: 0.8212\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5772 - accuracy: 0.8115\n",
            "Improved CNN Test accuracy: 0.8115000128746033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHguCFINTk2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}